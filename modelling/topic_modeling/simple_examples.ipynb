{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primary inspirations:\n",
    "\n",
    "- https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import string\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/kenneth/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/kenneth/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Install nltk things\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get document-topic matrix\n",
    "def get_document_topic_matrix(model, bow):\n",
    "    x = []\n",
    "    for d in bow:\n",
    "        # Get document's topics\n",
    "        doc_topics = lda.get_document_topics(d)\n",
    "        \n",
    "        # Extract just the document-topic probabilities\n",
    "        x.append([i[1] for i in doc_topics])\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case 1: 3 docs, 1 topic per doc\n",
    "\n",
    "Expect to see three topics, with the majority of the probability weights to correspond to the known topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['a1', 'a2', 'a3'], ['b1', 'b2', 'b3'], ['c1', 'c2', 'c3']]\n"
     ]
    }
   ],
   "source": [
    "# Create \"docs\"\n",
    "docs = [\n",
    "    'a1 a2 a3',\n",
    "    'b1 b2 b3',\n",
    "    'c1 c2 c3',    \n",
    "]\n",
    "\n",
    "# Split by space\n",
    "docs = [d.split() for d in docs]\n",
    "\n",
    "# Inspect\n",
    "print(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 1), (1, 1), (2, 1)], [(3, 1), (4, 1), (5, 1)], [(6, 1), (7, 1), (8, 1)]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create dictionary\n",
    "dic = corpora.Dictionary(docs)\n",
    "\n",
    "# Create bow matrix\n",
    "bow = [dic.doc2bow(doc) for doc in docs]\n",
    "\n",
    "# Inspect\n",
    "bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "lda = gensim.models.ldamodel.LdaModel(\n",
    "    bow,\n",
    "    num_topics=3,\n",
    "    id2word = dic,\n",
    "    passes=50,\n",
    "    random_state=666\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.222*\"a1\" + 0.222*\"a2\" + 0.222*\"a3\" + 0.056*\"b1\" + 0.056*\"b2\" + 0.056*\"b3\" + 0.056*\"c1\" + 0.056*\"c3\" + 0.056*\"c2\"'),\n",
       " (1,\n",
       "  '0.222*\"c1\" + 0.222*\"c2\" + 0.222*\"c3\" + 0.056*\"a3\" + 0.056*\"b2\" + 0.056*\"b3\" + 0.056*\"a1\" + 0.056*\"a2\" + 0.056*\"b1\"'),\n",
       " (2,\n",
       "  '0.222*\"b1\" + 0.222*\"b2\" + 0.222*\"b3\" + 0.056*\"a2\" + 0.056*\"a3\" + 0.056*\"c3\" + 0.056*\"a1\" + 0.056*\"c1\" + 0.056*\"c2\"')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect topics\n",
    "lda.show_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.83, 0.08, 0.08],\n",
       "       [0.08, 0.08, 0.83],\n",
       "       [0.08, 0.83, 0.08]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Document-topic matrix\n",
    "np.round(get_document_topic_matrix(lda, bow), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.22, 0.22, 0.22, 0.06, 0.06, 0.06, 0.06, 0.06, 0.06],\n",
       "       [0.06, 0.06, 0.06, 0.06, 0.06, 0.06, 0.22, 0.22, 0.22],\n",
       "       [0.06, 0.06, 0.06, 0.22, 0.22, 0.22, 0.06, 0.06, 0.06]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Topic-term matrix\n",
    "np.round(lda.get_topics(), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case 1.1: Many docs\n",
    "\n",
    "A little surprised that the off-topic words have such a high relative probability of appearing the topic (~6% for each word that doesn't appear at all in the docs with the topics).  But this might be primarily a sample size thing.\n",
    "\n",
    "Repeat Case 1 but instead have ~1k randomly sampled docs from the three used in Case 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['a1', 'a2', 'a3'], ['c1', 'c2', 'c3'], ['b1', 'b2', 'b3'], ['c1', 'c2', 'c3'], ['c1', 'c2', 'c3'], ['c1', 'c2', 'c3'], ['b1', 'b2', 'b3'], ['c1', 'c2', 'c3'], ['a1', 'a2', 'a3'], ['b1', 'b2', 'b3']]\n"
     ]
    }
   ],
   "source": [
    "# Create \"docs\"\n",
    "np.random.seed(666)\n",
    "\n",
    "docs_sample = np.random.choice(['a', 'b', 'c'], size=100)\n",
    "\n",
    "docs = [f'{x}1 {x}2 {x}3' for x in docs_sample]\n",
    "\n",
    "# Split by space\n",
    "docs = [d.split() for d in docs]\n",
    "\n",
    "# Inspect\n",
    "print(docs[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 1), (1, 1), (2, 1)],\n",
       " [(3, 1), (4, 1), (5, 1)],\n",
       " [(6, 1), (7, 1), (8, 1)],\n",
       " [(3, 1), (4, 1), (5, 1)],\n",
       " [(3, 1), (4, 1), (5, 1)],\n",
       " [(3, 1), (4, 1), (5, 1)],\n",
       " [(6, 1), (7, 1), (8, 1)],\n",
       " [(3, 1), (4, 1), (5, 1)],\n",
       " [(0, 1), (1, 1), (2, 1)],\n",
       " [(6, 1), (7, 1), (8, 1)]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create dictionary\n",
    "dic = corpora.Dictionary(docs)\n",
    "\n",
    "# Create bow matrix\n",
    "bow = [dic.doc2bow(doc) for doc in docs]\n",
    "\n",
    "# Inspect\n",
    "bow[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "lda = gensim.models.ldamodel.LdaModel(\n",
    "    bow,\n",
    "    num_topics = 3,\n",
    "    id2word = dic,\n",
    "    passes=50,\n",
    "    random_state=666\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.327*\"a1\" + 0.327*\"a2\" + 0.327*\"a3\" + 0.003*\"c1\" + 0.003*\"c2\" + 0.003*\"c3\" + 0.003*\"b3\" + 0.003*\"b1\" + 0.003*\"b2\"'),\n",
       " (1,\n",
       "  '0.326*\"b1\" + 0.326*\"b2\" + 0.326*\"b3\" + 0.004*\"a3\" + 0.004*\"a1\" + 0.004*\"a2\" + 0.004*\"c3\" + 0.004*\"c2\" + 0.004*\"c1\"'),\n",
       " (2,\n",
       "  '0.327*\"c1\" + 0.327*\"c2\" + 0.327*\"c3\" + 0.003*\"a3\" + 0.003*\"a2\" + 0.003*\"a1\" + 0.003*\"b3\" + 0.003*\"b1\" + 0.003*\"b2\"')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect topics\n",
    "lda.show_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.83, 0.08, 0.08],\n",
       "       [0.08, 0.08, 0.83],\n",
       "       [0.08, 0.83, 0.08],\n",
       "       [0.08, 0.08, 0.83],\n",
       "       [0.08, 0.08, 0.83]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Document-topic matrix\n",
    "np.round(get_document_topic_matrix(lda, bow), 2)[:5, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.33, 0.33, 0.33, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.33, 0.33, 0.33],\n",
       "       [0.  , 0.  , 0.  , 0.33, 0.33, 0.33, 0.  , 0.  , 0.  ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Topic-term matrix\n",
    "np.round(lda.get_topics(), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case 2: 2 equal topics per doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['a1', 'a2', 'a3', 'b1', 'b2', 'b3'], ['b1', 'b2', 'b3', 'c1', 'c2', 'c3'], ['c1', 'c2', 'c3', 'a1', 'a2', 'a3']]\n"
     ]
    }
   ],
   "source": [
    "# Create \"docs\"\n",
    "docs = [\n",
    "    'a1 a2 a3 b1 b2 b3',\n",
    "    'b1 b2 b3 c1 c2 c3',\n",
    "    'c1 c2 c3 a1 a2 a3',    \n",
    "]\n",
    "\n",
    "# Split by space\n",
    "docs = [d.split() for d in docs]\n",
    "\n",
    "# Inspect\n",
    "print(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1)],\n",
       " [(3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1)],\n",
       " [(0, 1), (1, 1), (2, 1), (6, 1), (7, 1), (8, 1)]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create dictionary\n",
    "dic = corpora.Dictionary(docs)\n",
    "\n",
    "# Create bow matrix\n",
    "bow = [dic.doc2bow(doc) for doc in docs]\n",
    "\n",
    "# Inspect\n",
    "bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "lda = gensim.models.ldamodel.LdaModel(\n",
    "    bow,\n",
    "    num_topics=3,\n",
    "    id2word = dic,\n",
    "    passes=50,\n",
    "    random_state=666\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.192*\"a2\" + 0.192*\"a1\" + 0.192*\"a3\" + 0.111*\"b1\" + 0.111*\"b2\" + 0.111*\"b3\" + 0.030*\"c3\" + 0.030*\"c1\" + 0.030*\"c2\"'),\n",
       " (1,\n",
       "  '0.192*\"c2\" + 0.192*\"c1\" + 0.192*\"c3\" + 0.111*\"b2\" + 0.111*\"b3\" + 0.111*\"b1\" + 0.030*\"a3\" + 0.030*\"a1\" + 0.030*\"a2\"'),\n",
       " (2,\n",
       "  '0.111*\"b3\" + 0.111*\"b2\" + 0.111*\"b1\" + 0.111*\"a3\" + 0.111*\"a2\" + 0.111*\"a1\" + 0.111*\"c3\" + 0.111*\"c1\" + 0.111*\"c2\"')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect topics\n",
    "lda.show_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.19, 0.19, 0.19, 0.11, 0.11, 0.11, 0.03, 0.03, 0.03],\n",
       "       [0.03, 0.03, 0.03, 0.11, 0.11, 0.11, 0.19, 0.19, 0.19],\n",
       "       [0.11, 0.11, 0.11, 0.11, 0.11, 0.11, 0.11, 0.11, 0.11]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Topic-term matrix\n",
    "np.round(lda.get_topics(), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9 , 0.05, 0.05],\n",
       "       [0.05, 0.9 , 0.05],\n",
       "       [0.48, 0.48, 0.05]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Document-topic matrix\n",
    "np.round(get_document_topic_matrix(lda, bow), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case 2.1: Many docs\n",
    "\n",
    "A little surprised that one of the topics has \"everything\" as an important element.  But this might also be primarily a sample size thing.\n",
    "\n",
    "Repeat Case 2 but instead have ~1k randomly sampled docs from the three used in Case 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['b1', 'b2', 'b3', 'c1', 'c2', 'c3'], ['a1', 'a2', 'a3', 'b1', 'b2', 'b3'], ['a1', 'a2', 'a3', 'b1', 'b2', 'b3'], ['b1', 'b2', 'b3', 'c1', 'c2', 'c3'], ['c1', 'c2', 'c3', 'a1', 'a2', 'a3'], ['c1', 'c2', 'c3', 'a1', 'a2', 'a3'], ['c1', 'c2', 'c3', 'a1', 'a2', 'a3'], ['a1', 'a2', 'a3', 'b1', 'b2', 'b3'], ['a1', 'a2', 'a3', 'b1', 'b2', 'b3'], ['b1', 'b2', 'b3', 'c1', 'c2', 'c3']]\n"
     ]
    }
   ],
   "source": [
    "# Create \"docs\"\n",
    "np.random.seed(1337)\n",
    "\n",
    "docs_sample = np.random.choice(['a', 'b', 'c'], size=100)\n",
    "\n",
    "def gen_string(x):\n",
    "    if x == 'a':\n",
    "        return 'a1 a2 a3 b1 b2 b3'\n",
    "    elif x == 'b':\n",
    "        return 'b1 b2 b3 c1 c2 c3'\n",
    "    elif x == 'c':\n",
    "        return 'c1 c2 c3 a1 a2 a3'\n",
    "    raise ValueError(f'value {x} not supported')\n",
    "\n",
    "docs = [gen_string(x) for x in docs_sample]\n",
    "\n",
    "# Split by space\n",
    "docs = [d.split() for d in docs]\n",
    "\n",
    "# Inspect\n",
    "print(docs[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1)],\n",
       " [(0, 1), (1, 1), (2, 1), (6, 1), (7, 1), (8, 1)],\n",
       " [(0, 1), (1, 1), (2, 1), (6, 1), (7, 1), (8, 1)],\n",
       " [(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1)],\n",
       " [(3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1)]]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create dictionary\n",
    "dic = corpora.Dictionary(docs)\n",
    "\n",
    "# Create bow matrix\n",
    "bow = [dic.doc2bow(doc) for doc in docs]\n",
    "\n",
    "# Inspect\n",
    "bow[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "lda = gensim.models.ldamodel.LdaModel(\n",
    "    bow,\n",
    "    num_topics=3,\n",
    "    id2word = dic,\n",
    "    passes=50,\n",
    "    random_state=666\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.166*\"a1\" + 0.166*\"a2\" + 0.166*\"a3\" + 0.166*\"b1\" + 0.166*\"b2\" + 0.166*\"b3\" + 0.002*\"c1\" + 0.002*\"c2\" + 0.002*\"c3\"'),\n",
       " (1,\n",
       "  '0.166*\"a2\" + 0.166*\"a1\" + 0.166*\"a3\" + 0.166*\"c2\" + 0.166*\"c3\" + 0.166*\"c1\" + 0.002*\"b3\" + 0.002*\"b1\" + 0.002*\"b2\"'),\n",
       " (2,\n",
       "  '0.166*\"b2\" + 0.166*\"b3\" + 0.166*\"b1\" + 0.166*\"c1\" + 0.166*\"c2\" + 0.166*\"c3\" + 0.002*\"a3\" + 0.002*\"a2\" + 0.002*\"a1\"')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect topics\n",
    "lda.show_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.17, 0.17, 0.17, 0.  , 0.  , 0.  , 0.17, 0.17, 0.17],\n",
       "       [0.  , 0.  , 0.  , 0.17, 0.17, 0.17, 0.17, 0.17, 0.17],\n",
       "       [0.17, 0.17, 0.17, 0.17, 0.17, 0.17, 0.  , 0.  , 0.  ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Topic-term matrix\n",
    "np.round(lda.get_topics(), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.05, 0.05, 0.9 ],\n",
       "       [0.9 , 0.05, 0.05],\n",
       "       [0.9 , 0.05, 0.05],\n",
       "       [0.05, 0.05, 0.9 ],\n",
       "       [0.05, 0.9 , 0.05]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Document-topic matrix\n",
    "np.round(get_document_topic_matrix(lda, bow), 2)[:5, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much better, though interesting that we're still seeing some \"off topic\" percentages of generally ~10% per doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case 3: 3 cascading topics per doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['a1', 'a2', 'a3', 'b1', 'b2', 'c1'], ['b1', 'b2', 'b3', 'c1', 'c2', 'a1'], ['c1', 'c2', 'c3', 'a1', 'a2', 'b1']]\n"
     ]
    }
   ],
   "source": [
    "# Create \"docs\"\n",
    "docs = [\n",
    "    'a1 a2 a3 b1 b2 c1',\n",
    "    'b1 b2 b3 c1 c2 a1',\n",
    "    'c1 c2 c3 a1 a2 b1',    \n",
    "]\n",
    "\n",
    "# Split by space\n",
    "docs = [d.split() for d in docs]\n",
    "\n",
    "# Inspect\n",
    "print(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1)],\n",
       " [(0, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1)],\n",
       " [(0, 1), (1, 1), (3, 1), (5, 1), (7, 1), (8, 1)]]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create dictionary\n",
    "dic = corpora.Dictionary(docs)\n",
    "\n",
    "# Create bow matrix\n",
    "bow = [dic.doc2bow(doc) for doc in docs]\n",
    "\n",
    "# Inspect\n",
    "bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "lda = gensim.models.ldamodel.LdaModel(\n",
    "    bow,\n",
    "    num_topics=3,\n",
    "    id2word = dic,\n",
    "    passes=50,\n",
    "    random_state=666\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.148*\"a1\" + 0.148*\"b1\" + 0.148*\"c1\" + 0.148*\"a2\" + 0.148*\"b2\" + 0.148*\"a3\" + 0.037*\"c2\" + 0.037*\"c3\" + 0.037*\"b3\"'),\n",
       " (1,\n",
       "  '0.148*\"c1\" + 0.148*\"a1\" + 0.148*\"b1\" + 0.148*\"c2\" + 0.148*\"b2\" + 0.148*\"b3\" + 0.037*\"a2\" + 0.037*\"a3\" + 0.037*\"c3\"'),\n",
       " (2,\n",
       "  '0.148*\"c1\" + 0.148*\"b1\" + 0.148*\"a1\" + 0.148*\"c2\" + 0.148*\"a2\" + 0.148*\"c3\" + 0.037*\"b2\" + 0.037*\"a3\" + 0.037*\"b3\"')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect topics\n",
    "lda.show_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.04, 0.04, 0.04],\n",
       "       [0.15, 0.04, 0.04, 0.15, 0.15, 0.15, 0.15, 0.15, 0.04],\n",
       "       [0.15, 0.15, 0.04, 0.15, 0.04, 0.15, 0.04, 0.15, 0.15]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Topic-term matrix\n",
    "np.round(lda.get_topics(), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.89, 0.05, 0.05],\n",
       "       [0.05, 0.89, 0.05],\n",
       "       [0.05, 0.05, 0.89]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Document-topic matrix\n",
    "np.round(get_document_topic_matrix(lda, bow), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case 2.1: Many docs\n",
    "\n",
    "Directionally isn't bad, but yet again it's surprising it's not distinguishing between primary and secondary topics.  But this might also be primarily a sample size thing.\n",
    "\n",
    "Repeat Case 3 but instead have ~1k randomly sampled docs from the three used in Case 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['c1', 'c2', 'c3', 'a1', 'a2', 'b1'], ['b1', 'b2', 'b3', 'c1', 'c2', 'a1'], ['c1', 'c2', 'c3', 'a1', 'a2', 'b1'], ['c1', 'c2', 'c3', 'a1', 'a2', 'b1'], ['a1', 'a2', 'a3', 'b1', 'b2', 'c1'], ['a1', 'a2', 'a3', 'b1', 'b2', 'c1'], ['c1', 'c2', 'c3', 'a1', 'a2', 'b1'], ['c1', 'c2', 'c3', 'a1', 'a2', 'b1'], ['c1', 'c2', 'c3', 'a1', 'a2', 'b1'], ['c1', 'c2', 'c3', 'a1', 'a2', 'b1']]\n"
     ]
    }
   ],
   "source": [
    "# Create \"docs\"\n",
    "np.random.seed(369)\n",
    "\n",
    "docs_sample = np.random.choice(['a', 'b', 'c'], size=100)\n",
    "\n",
    "def gen_string(x):\n",
    "    if x == 'a':\n",
    "        return 'a1 a2 a3 b1 b2 c1'\n",
    "    elif x == 'b':\n",
    "        return 'b1 b2 b3 c1 c2 a1'\n",
    "    elif x == 'c':\n",
    "        return 'c1 c2 c3 a1 a2 b1'\n",
    "    raise ValueError(f'value {x} not supported')\n",
    "\n",
    "docs = [gen_string(x) for x in docs_sample]\n",
    "\n",
    "# Split by space\n",
    "docs = [d.split() for d in docs]\n",
    "\n",
    "# Inspect\n",
    "print(docs[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1)],\n",
       " [(0, 1), (2, 1), (3, 1), (4, 1), (6, 1), (7, 1)],\n",
       " [(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1)],\n",
       " [(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1)],\n",
       " [(0, 1), (1, 1), (2, 1), (3, 1), (6, 1), (8, 1)]]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create dictionary\n",
    "dic = corpora.Dictionary(docs)\n",
    "\n",
    "# Create bow matrix\n",
    "bow = [dic.doc2bow(doc) for doc in docs]\n",
    "\n",
    "# Inspect\n",
    "bow[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "lda = gensim.models.ldamodel.LdaModel(\n",
    "    bow,\n",
    "    num_topics=3,\n",
    "    id2word = dic,\n",
    "    passes=50,\n",
    "    random_state=666\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.166*\"a2\" + 0.166*\"a3\" + 0.166*\"a1\" + 0.166*\"c1\" + 0.166*\"b1\" + 0.166*\"b2\" + 0.002*\"c2\" + 0.002*\"c3\" + 0.002*\"b3\"'),\n",
       " (1,\n",
       "  '0.166*\"b1\" + 0.166*\"a1\" + 0.166*\"c1\" + 0.165*\"c2\" + 0.165*\"b2\" + 0.165*\"b3\" + 0.002*\"a2\" + 0.002*\"c3\" + 0.002*\"a3\"'),\n",
       " (2,\n",
       "  '0.166*\"c3\" + 0.166*\"a2\" + 0.166*\"c2\" + 0.166*\"b1\" + 0.166*\"c1\" + 0.166*\"a1\" + 0.001*\"b2\" + 0.001*\"a3\" + 0.001*\"b3\"')]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect topics\n",
    "lda.show_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.17, 0.17, 0.17, 0.17, 0.  , 0.  , 0.17, 0.  , 0.17],\n",
       "       [0.17, 0.  , 0.17, 0.17, 0.17, 0.  , 0.17, 0.16, 0.  ],\n",
       "       [0.17, 0.17, 0.17, 0.17, 0.17, 0.17, 0.  , 0.  , 0.  ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Topic-term matrix\n",
    "np.round(lda.get_topics(), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.05, 0.05, 0.89],\n",
       "       [0.05, 0.89, 0.05],\n",
       "       [0.05, 0.05, 0.89],\n",
       "       [0.05, 0.05, 0.89],\n",
       "       [0.89, 0.05, 0.05]], dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Document-topic matrix\n",
    "np.round(get_document_topic_matrix(lda, bow), 2)[:5, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimal number of topics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
