{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primary inspirations:\n",
    "\n",
    "- https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kenneth/miniconda3/envs/topic_modeling/lib/python3.7/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import string\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/kenneth/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/kenneth/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Install nltk things\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get document-topic matrix\n",
    "def get_document_topic_matrix(model, bow):\n",
    "    x = []\n",
    "    for d in bow:\n",
    "        # Get document's topics\n",
    "        doc_topics = lda.get_document_topics(d)\n",
    "        \n",
    "        # Extract just the document-topic probabilities\n",
    "        x.append([i[1] for i in doc_topics])\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case 1: 3 docs, 1 topic per doc\n",
    "\n",
    "Expect to see three topics, with the majority of the probability weights to correspond to the known topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['a1', 'a2', 'a3'], ['b1', 'b2', 'b3'], ['c1', 'c2', 'c3']]\n"
     ]
    }
   ],
   "source": [
    "# Create \"docs\"\n",
    "docs = [\n",
    "    'a1 a2 a3',\n",
    "    'b1 b2 b3',\n",
    "    'c1 c2 c3',    \n",
    "]\n",
    "\n",
    "# Split by space\n",
    "docs = [d.split() for d in docs]\n",
    "\n",
    "# Inspect\n",
    "print(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 1), (1, 1), (2, 1)], [(3, 1), (4, 1), (5, 1)], [(6, 1), (7, 1), (8, 1)]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create dictionary\n",
    "dic = corpora.Dictionary(docs)\n",
    "\n",
    "# Create bow matrix\n",
    "bow = [dic.doc2bow(doc) for doc in docs]\n",
    "\n",
    "# Inspect\n",
    "bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "lda = gensim.models.ldamodel.LdaModel(\n",
    "    bow,\n",
    "    num_topics=3,\n",
    "    id2word = dic,\n",
    "    passes=50,\n",
    "    random_state=666\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.222*\"a1\" + 0.222*\"a2\" + 0.222*\"a3\" + 0.056*\"b1\" + 0.056*\"b2\" + 0.056*\"b3\" + 0.056*\"c1\" + 0.056*\"c3\" + 0.056*\"c2\"'),\n",
       " (1,\n",
       "  '0.222*\"c1\" + 0.222*\"c2\" + 0.222*\"c3\" + 0.056*\"a3\" + 0.056*\"b2\" + 0.056*\"b3\" + 0.056*\"a1\" + 0.056*\"a2\" + 0.056*\"b1\"'),\n",
       " (2,\n",
       "  '0.222*\"b1\" + 0.222*\"b2\" + 0.222*\"b3\" + 0.056*\"a2\" + 0.056*\"a3\" + 0.056*\"c3\" + 0.056*\"a1\" + 0.056*\"c1\" + 0.056*\"c2\"')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect topics\n",
    "lda.show_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.83, 0.08, 0.08],\n",
       "       [0.08, 0.08, 0.83],\n",
       "       [0.08, 0.83, 0.08]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Document-topic matrix\n",
    "np.round(get_document_topic_matrix(lda, bow), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.22, 0.22, 0.22, 0.06, 0.06, 0.06, 0.06, 0.06, 0.06],\n",
       "       [0.06, 0.06, 0.06, 0.06, 0.06, 0.06, 0.22, 0.22, 0.22],\n",
       "       [0.06, 0.06, 0.06, 0.22, 0.22, 0.22, 0.06, 0.06, 0.06]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Topic-term matrix\n",
    "np.round(lda.get_topics(), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case 1.1: Many docs\n",
    "\n",
    "A little surprised that the off-topic words have such a high relative probability of appearing the topic (~6% for each word that doesn't appear at all in the docs with the topics).  But this might be primarily a sample size thing.\n",
    "\n",
    "Repeat Case 1 but instead have ~1k randomly sampled docs from the three used in Case 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['a1', 'a2', 'a3'], ['c1', 'c2', 'c3'], ['b1', 'b2', 'b3'], ['c1', 'c2', 'c3'], ['c1', 'c2', 'c3'], ['c1', 'c2', 'c3'], ['b1', 'b2', 'b3'], ['c1', 'c2', 'c3'], ['a1', 'a2', 'a3'], ['b1', 'b2', 'b3']]\n"
     ]
    }
   ],
   "source": [
    "# Create \"docs\"\n",
    "np.random.seed(666)\n",
    "\n",
    "docs_sample = np.random.choice(['a', 'b', 'c'], size=100)\n",
    "\n",
    "docs = [f'{x}1 {x}2 {x}3' for x in docs_sample]\n",
    "\n",
    "# Split by space\n",
    "docs = [d.split() for d in docs]\n",
    "\n",
    "# Inspect\n",
    "print(docs[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 1), (1, 1), (2, 1)],\n",
       " [(3, 1), (4, 1), (5, 1)],\n",
       " [(6, 1), (7, 1), (8, 1)],\n",
       " [(3, 1), (4, 1), (5, 1)],\n",
       " [(3, 1), (4, 1), (5, 1)],\n",
       " [(3, 1), (4, 1), (5, 1)],\n",
       " [(6, 1), (7, 1), (8, 1)],\n",
       " [(3, 1), (4, 1), (5, 1)],\n",
       " [(0, 1), (1, 1), (2, 1)],\n",
       " [(6, 1), (7, 1), (8, 1)]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create dictionary\n",
    "dic = corpora.Dictionary(docs)\n",
    "\n",
    "# Create bow matrix\n",
    "bow = [dic.doc2bow(doc) for doc in docs]\n",
    "\n",
    "# Inspect\n",
    "bow[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "lda = gensim.models.ldamodel.LdaModel(\n",
    "    bow,\n",
    "    num_topics = 3,\n",
    "    id2word = dic,\n",
    "    passes=50,\n",
    "    random_state=666\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.327*\"a1\" + 0.327*\"a2\" + 0.327*\"a3\" + 0.003*\"c1\" + 0.003*\"c2\" + 0.003*\"c3\" + 0.003*\"b3\" + 0.003*\"b1\" + 0.003*\"b2\"'),\n",
       " (1,\n",
       "  '0.326*\"b1\" + 0.326*\"b2\" + 0.326*\"b3\" + 0.004*\"a3\" + 0.004*\"a1\" + 0.004*\"a2\" + 0.004*\"c3\" + 0.004*\"c2\" + 0.004*\"c1\"'),\n",
       " (2,\n",
       "  '0.327*\"c1\" + 0.327*\"c2\" + 0.327*\"c3\" + 0.003*\"a3\" + 0.003*\"a2\" + 0.003*\"a1\" + 0.003*\"b3\" + 0.003*\"b1\" + 0.003*\"b2\"')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect topics\n",
    "lda.show_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.83, 0.08, 0.08],\n",
       "       [0.08, 0.08, 0.83],\n",
       "       [0.08, 0.83, 0.08],\n",
       "       [0.08, 0.08, 0.83],\n",
       "       [0.08, 0.08, 0.83]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Document-topic matrix\n",
    "np.round(get_document_topic_matrix(lda, bow), 2)[:5, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.33, 0.33, 0.33, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.33, 0.33, 0.33],\n",
       "       [0.  , 0.  , 0.  , 0.33, 0.33, 0.33, 0.  , 0.  , 0.  ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Topic-term matrix\n",
    "np.round(lda.get_topics(), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case 2: 2 equal topics per doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['a1', 'a2', 'a3', 'b1', 'b2', 'b3'], ['b1', 'b2', 'b3', 'c1', 'c2', 'c3'], ['c1', 'c2', 'c3', 'a1', 'a2', 'a3']]\n"
     ]
    }
   ],
   "source": [
    "# Create \"docs\"\n",
    "docs = [\n",
    "    'a1 a2 a3 b1 b2 b3',\n",
    "    'b1 b2 b3 c1 c2 c3',\n",
    "    'c1 c2 c3 a1 a2 a3',    \n",
    "]\n",
    "\n",
    "# Split by space\n",
    "docs = [d.split() for d in docs]\n",
    "\n",
    "# Inspect\n",
    "print(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1)],\n",
       " [(3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1)],\n",
       " [(0, 1), (1, 1), (2, 1), (6, 1), (7, 1), (8, 1)]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create dictionary\n",
    "dic = corpora.Dictionary(docs)\n",
    "\n",
    "# Create bow matrix\n",
    "bow = [dic.doc2bow(doc) for doc in docs]\n",
    "\n",
    "# Inspect\n",
    "bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "lda = gensim.models.ldamodel.LdaModel(\n",
    "    bow,\n",
    "    num_topics=3,\n",
    "    id2word = dic,\n",
    "    passes=50,\n",
    "    random_state=666\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.192*\"a2\" + 0.192*\"a1\" + 0.192*\"a3\" + 0.111*\"b1\" + 0.111*\"b2\" + 0.111*\"b3\" + 0.030*\"c3\" + 0.030*\"c1\" + 0.030*\"c2\"'),\n",
       " (1,\n",
       "  '0.192*\"c2\" + 0.192*\"c1\" + 0.192*\"c3\" + 0.111*\"b2\" + 0.111*\"b3\" + 0.111*\"b1\" + 0.030*\"a3\" + 0.030*\"a1\" + 0.030*\"a2\"'),\n",
       " (2,\n",
       "  '0.111*\"b3\" + 0.111*\"b2\" + 0.111*\"b1\" + 0.111*\"a3\" + 0.111*\"a2\" + 0.111*\"a1\" + 0.111*\"c3\" + 0.111*\"c1\" + 0.111*\"c2\"')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect topics\n",
    "lda.show_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.19, 0.19, 0.19, 0.11, 0.11, 0.11, 0.03, 0.03, 0.03],\n",
       "       [0.03, 0.03, 0.03, 0.11, 0.11, 0.11, 0.19, 0.19, 0.19],\n",
       "       [0.11, 0.11, 0.11, 0.11, 0.11, 0.11, 0.11, 0.11, 0.11]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Topic-term matrix\n",
    "np.round(lda.get_topics(), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9 , 0.05, 0.05],\n",
       "       [0.05, 0.9 , 0.05],\n",
       "       [0.48, 0.48, 0.05]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Document-topic matrix\n",
    "np.round(get_document_topic_matrix(lda, bow), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case 2.1: Many docs\n",
    "\n",
    "A little surprised that one of the topics has \"everything\" as an important element.  But this might also be primarily a sample size thing.\n",
    "\n",
    "Repeat Case 2 but instead have ~1k randomly sampled docs from the three used in Case 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['b1', 'b2', 'b3', 'c1', 'c2', 'c3'], ['a1', 'a2', 'a3', 'b1', 'b2', 'b3'], ['a1', 'a2', 'a3', 'b1', 'b2', 'b3'], ['b1', 'b2', 'b3', 'c1', 'c2', 'c3'], ['c1', 'c2', 'c3', 'a1', 'a2', 'a3'], ['c1', 'c2', 'c3', 'a1', 'a2', 'a3'], ['c1', 'c2', 'c3', 'a1', 'a2', 'a3'], ['a1', 'a2', 'a3', 'b1', 'b2', 'b3'], ['a1', 'a2', 'a3', 'b1', 'b2', 'b3'], ['b1', 'b2', 'b3', 'c1', 'c2', 'c3']]\n"
     ]
    }
   ],
   "source": [
    "# Create \"docs\"\n",
    "np.random.seed(1337)\n",
    "\n",
    "docs_sample = np.random.choice(['a', 'b', 'c'], size=100)\n",
    "\n",
    "def gen_string(x):\n",
    "    if x == 'a':\n",
    "        return 'a1 a2 a3 b1 b2 b3'\n",
    "    elif x == 'b':\n",
    "        return 'b1 b2 b3 c1 c2 c3'\n",
    "    elif x == 'c':\n",
    "        return 'c1 c2 c3 a1 a2 a3'\n",
    "    raise ValueError(f'value {x} not supported')\n",
    "\n",
    "docs = [gen_string(x) for x in docs_sample]\n",
    "\n",
    "# Split by space\n",
    "docs = [d.split() for d in docs]\n",
    "\n",
    "# Inspect\n",
    "print(docs[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1)],\n",
       " [(0, 1), (1, 1), (2, 1), (6, 1), (7, 1), (8, 1)],\n",
       " [(0, 1), (1, 1), (2, 1), (6, 1), (7, 1), (8, 1)],\n",
       " [(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1)],\n",
       " [(3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1)]]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create dictionary\n",
    "dic = corpora.Dictionary(docs)\n",
    "\n",
    "# Create bow matrix\n",
    "bow = [dic.doc2bow(doc) for doc in docs]\n",
    "\n",
    "# Inspect\n",
    "bow[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "lda = gensim.models.ldamodel.LdaModel(\n",
    "    bow,\n",
    "    num_topics=3,\n",
    "    id2word = dic,\n",
    "    passes=50,\n",
    "    random_state=666\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.166*\"a1\" + 0.166*\"a2\" + 0.166*\"a3\" + 0.166*\"b1\" + 0.166*\"b2\" + 0.166*\"b3\" + 0.002*\"c1\" + 0.002*\"c2\" + 0.002*\"c3\"'),\n",
       " (1,\n",
       "  '0.166*\"a2\" + 0.166*\"a1\" + 0.166*\"a3\" + 0.166*\"c2\" + 0.166*\"c3\" + 0.166*\"c1\" + 0.002*\"b3\" + 0.002*\"b1\" + 0.002*\"b2\"'),\n",
       " (2,\n",
       "  '0.166*\"b2\" + 0.166*\"b3\" + 0.166*\"b1\" + 0.166*\"c1\" + 0.166*\"c2\" + 0.166*\"c3\" + 0.002*\"a3\" + 0.002*\"a2\" + 0.002*\"a1\"')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect topics\n",
    "lda.show_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.17, 0.17, 0.17, 0.  , 0.  , 0.  , 0.17, 0.17, 0.17],\n",
       "       [0.  , 0.  , 0.  , 0.17, 0.17, 0.17, 0.17, 0.17, 0.17],\n",
       "       [0.17, 0.17, 0.17, 0.17, 0.17, 0.17, 0.  , 0.  , 0.  ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Topic-term matrix\n",
    "np.round(lda.get_topics(), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.05, 0.05, 0.9 ],\n",
       "       [0.9 , 0.05, 0.05],\n",
       "       [0.9 , 0.05, 0.05],\n",
       "       [0.05, 0.05, 0.9 ],\n",
       "       [0.05, 0.9 , 0.05]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Document-topic matrix\n",
    "np.round(get_document_topic_matrix(lda, bow), 2)[:5, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much better, though interesting that we're still seeing some \"off topic\" percentages of generally ~10% per doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case 3: 3 cascading topics per doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['a1', 'a2', 'a3', 'b1', 'b2', 'c1'], ['b1', 'b2', 'b3', 'c1', 'c2', 'a1'], ['c1', 'c2', 'c3', 'a1', 'a2', 'b1']]\n"
     ]
    }
   ],
   "source": [
    "# Create \"docs\"\n",
    "docs = [\n",
    "    'a1 a2 a3 b1 b2 c1',\n",
    "    'b1 b2 b3 c1 c2 a1',\n",
    "    'c1 c2 c3 a1 a2 b1',    \n",
    "]\n",
    "\n",
    "# Split by space\n",
    "docs = [d.split() for d in docs]\n",
    "\n",
    "# Inspect\n",
    "print(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1)],\n",
       " [(0, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1)],\n",
       " [(0, 1), (1, 1), (3, 1), (5, 1), (7, 1), (8, 1)]]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create dictionary\n",
    "dic = corpora.Dictionary(docs)\n",
    "\n",
    "# Create bow matrix\n",
    "bow = [dic.doc2bow(doc) for doc in docs]\n",
    "\n",
    "# Inspect\n",
    "bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "lda = gensim.models.ldamodel.LdaModel(\n",
    "    bow,\n",
    "    num_topics=3,\n",
    "    id2word = dic,\n",
    "    passes=50,\n",
    "    random_state=666\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.148*\"a1\" + 0.148*\"b1\" + 0.148*\"c1\" + 0.148*\"a2\" + 0.148*\"b2\" + 0.148*\"a3\" + 0.037*\"c2\" + 0.037*\"c3\" + 0.037*\"b3\"'),\n",
       " (1,\n",
       "  '0.148*\"c1\" + 0.148*\"a1\" + 0.148*\"b1\" + 0.148*\"c2\" + 0.148*\"b2\" + 0.148*\"b3\" + 0.037*\"a2\" + 0.037*\"a3\" + 0.037*\"c3\"'),\n",
       " (2,\n",
       "  '0.148*\"c1\" + 0.148*\"b1\" + 0.148*\"a1\" + 0.148*\"c2\" + 0.148*\"a2\" + 0.148*\"c3\" + 0.037*\"b2\" + 0.037*\"a3\" + 0.037*\"b3\"')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect topics\n",
    "lda.show_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.04, 0.04, 0.04],\n",
       "       [0.15, 0.04, 0.04, 0.15, 0.15, 0.15, 0.15, 0.15, 0.04],\n",
       "       [0.15, 0.15, 0.04, 0.15, 0.04, 0.15, 0.04, 0.15, 0.15]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Topic-term matrix\n",
    "np.round(lda.get_topics(), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.89, 0.05, 0.05],\n",
       "       [0.05, 0.89, 0.05],\n",
       "       [0.05, 0.05, 0.89]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Document-topic matrix\n",
    "np.round(get_document_topic_matrix(lda, bow), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case 3.1: Many docs\n",
    "\n",
    "Directionally isn't bad, but yet again it's surprising it's not distinguishing between primary and secondary topics.  But this might also be primarily a sample size thing.\n",
    "\n",
    "Repeat Case 3 but instead have ~1k randomly sampled docs from the three used in Case 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['c1', 'c2', 'c3', 'a1', 'a2', 'b1'], ['b1', 'b2', 'b3', 'c1', 'c2', 'a1'], ['c1', 'c2', 'c3', 'a1', 'a2', 'b1'], ['c1', 'c2', 'c3', 'a1', 'a2', 'b1'], ['a1', 'a2', 'a3', 'b1', 'b2', 'c1'], ['a1', 'a2', 'a3', 'b1', 'b2', 'c1'], ['c1', 'c2', 'c3', 'a1', 'a2', 'b1'], ['c1', 'c2', 'c3', 'a1', 'a2', 'b1'], ['c1', 'c2', 'c3', 'a1', 'a2', 'b1'], ['c1', 'c2', 'c3', 'a1', 'a2', 'b1']]\n"
     ]
    }
   ],
   "source": [
    "# Create \"docs\"\n",
    "np.random.seed(369)\n",
    "\n",
    "docs_sample = np.random.choice(['a', 'b', 'c'], size=100)\n",
    "\n",
    "def gen_string(x):\n",
    "    if x == 'a':\n",
    "        return 'a1 a2 a3 b1 b2 c1'\n",
    "    elif x == 'b':\n",
    "        return 'b1 b2 b3 c1 c2 a1'\n",
    "    elif x == 'c':\n",
    "        return 'c1 c2 c3 a1 a2 b1'\n",
    "    raise ValueError(f'value {x} not supported')\n",
    "\n",
    "docs = [gen_string(x) for x in docs_sample]\n",
    "\n",
    "# Split by space\n",
    "docs = [d.split() for d in docs]\n",
    "\n",
    "# Inspect\n",
    "print(docs[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1)],\n",
       " [(0, 1), (2, 1), (3, 1), (4, 1), (6, 1), (7, 1)],\n",
       " [(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1)],\n",
       " [(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1)],\n",
       " [(0, 1), (1, 1), (2, 1), (3, 1), (6, 1), (8, 1)]]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create dictionary\n",
    "dic = corpora.Dictionary(docs)\n",
    "\n",
    "# Create bow matrix\n",
    "bow = [dic.doc2bow(doc) for doc in docs]\n",
    "\n",
    "# Inspect\n",
    "bow[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "lda = gensim.models.ldamodel.LdaModel(\n",
    "    bow,\n",
    "    num_topics=3,\n",
    "    id2word = dic,\n",
    "    passes=50,\n",
    "    random_state=666\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.166*\"a2\" + 0.166*\"a3\" + 0.166*\"a1\" + 0.166*\"c1\" + 0.166*\"b1\" + 0.166*\"b2\" + 0.002*\"c2\" + 0.002*\"c3\" + 0.002*\"b3\"'),\n",
       " (1,\n",
       "  '0.166*\"b1\" + 0.166*\"a1\" + 0.166*\"c1\" + 0.165*\"c2\" + 0.165*\"b2\" + 0.165*\"b3\" + 0.002*\"a2\" + 0.002*\"c3\" + 0.002*\"a3\"'),\n",
       " (2,\n",
       "  '0.166*\"c3\" + 0.166*\"a2\" + 0.166*\"c2\" + 0.166*\"b1\" + 0.166*\"c1\" + 0.166*\"a1\" + 0.001*\"b2\" + 0.001*\"a3\" + 0.001*\"b3\"')]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect topics\n",
    "lda.show_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.17, 0.17, 0.17, 0.17, 0.  , 0.  , 0.17, 0.  , 0.17],\n",
       "       [0.17, 0.  , 0.17, 0.17, 0.17, 0.  , 0.17, 0.16, 0.  ],\n",
       "       [0.17, 0.17, 0.17, 0.17, 0.17, 0.17, 0.  , 0.  , 0.  ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Topic-term matrix\n",
    "np.round(lda.get_topics(), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.05, 0.05, 0.89],\n",
       "       [0.05, 0.89, 0.05],\n",
       "       [0.05, 0.05, 0.89],\n",
       "       [0.05, 0.05, 0.89],\n",
       "       [0.89, 0.05, 0.05]], dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Document-topic matrix\n",
    "np.round(get_document_topic_matrix(lda, bow), 2)[:5, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case 4: Random number of topics\n",
    "\n",
    "Generate 1k docs with a randomly selected number of topics from the previously used 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['b1', 'b2', 'b3'], ['a1', 'a2', 'a3'], ['a1', 'a2', 'a3', 'b1', 'b2', 'b3'], ['a1', 'a2', 'a3'], ['c1', 'c2', 'c3', 'b1', 'b2', 'b3'], ['c1', 'c2', 'c3', 'a1', 'a2', 'a3', 'b1', 'b2', 'b3'], ['b1', 'b2', 'b3', 'a1', 'a2', 'a3', 'c1', 'c2', 'c3'], ['a1', 'a2', 'a3', 'b1', 'b2', 'b3', 'c1', 'c2', 'c3'], ['b1', 'b2', 'b3', 'c1', 'c2', 'c3', 'a1', 'a2', 'a3'], ['b1', 'b2', 'b3', 'a1', 'a2', 'a3']]\n"
     ]
    }
   ],
   "source": [
    "# Create \"docs\"\n",
    "np.random.seed(404)\n",
    "\n",
    "def gen_doc():\n",
    "    n_topics = np.random.randint(3) + 1\n",
    "    which_topics = np.random.choice(['a', 'b', 'c'], size=n_topics, replace=False)\n",
    "    \n",
    "    s = []\n",
    "    for t in which_topics:\n",
    "        s.append(f'{t}1 {t}2 {t}3')\n",
    "        \n",
    "    return ' '.join(s)\n",
    "\n",
    "docs = [gen_doc() for x in range(1000)]\n",
    "\n",
    "# Split by space\n",
    "docs = [d.split() for d in docs]\n",
    "\n",
    "# Inspect\n",
    "print(docs[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 1), (1, 1), (2, 1)],\n",
       " [(3, 1), (4, 1), (5, 1)],\n",
       " [(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1)],\n",
       " [(3, 1), (4, 1), (5, 1)],\n",
       " [(0, 1), (1, 1), (2, 1), (6, 1), (7, 1), (8, 1)]]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create dictionary\n",
    "dic = corpora.Dictionary(docs)\n",
    "\n",
    "# Create bow matrix\n",
    "bow = [dic.doc2bow(doc) for doc in docs]\n",
    "\n",
    "# Inspect\n",
    "bow[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "lda = gensim.models.ldamodel.LdaModel(\n",
    "    bow,\n",
    "    num_topics=3,\n",
    "    id2word = dic,\n",
    "    passes=50,\n",
    "    random_state=666\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.223*\"b1\" + 0.223*\"b2\" + 0.223*\"b3\" + 0.110*\"c1\" + 0.110*\"c3\" + 0.110*\"c2\" + 0.000*\"a1\" + 0.000*\"a2\" + 0.000*\"a3\"'),\n",
       " (1,\n",
       "  '0.229*\"c2\" + 0.229*\"c3\" + 0.229*\"c1\" + 0.104*\"a3\" + 0.104*\"a2\" + 0.104*\"a1\" + 0.000*\"b3\" + 0.000*\"b1\" + 0.000*\"b2\"'),\n",
       " (2,\n",
       "  '0.229*\"a3\" + 0.229*\"a2\" + 0.229*\"a1\" + 0.104*\"b3\" + 0.104*\"b2\" + 0.104*\"b1\" + 0.001*\"c3\" + 0.001*\"c2\" + 0.001*\"c1\"')]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect topics\n",
    "lda.show_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.22, 0.22, 0.22, 0.  , 0.  , 0.  , 0.11, 0.11, 0.11],\n",
       "       [0.  , 0.  , 0.  , 0.1 , 0.1 , 0.1 , 0.23, 0.23, 0.23],\n",
       "       [0.1 , 0.1 , 0.1 , 0.23, 0.23, 0.23, 0.  , 0.  , 0.  ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Topic-term matrix\n",
    "np.round(lda.get_topics(), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.83, 0.08, 0.09],\n",
       "       [0.08, 0.09, 0.83],\n",
       "       [0.06, 0.05, 0.89],\n",
       "       [0.08, 0.09, 0.83],\n",
       "       [0.89, 0.06, 0.05]], dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Document-topic matrix\n",
    "np.round(get_document_topic_matrix(lda, bow), 2)[:5, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case 5: Random number of topics and random sampling of words\n",
    "\n",
    "Generate 1k docs with a randomly selected number of topics with a random sampling of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['b1', 'b1', 'b2', 'b3', 'c3'], ['a5'], ['a5'], ['b5', 'b5', 'a2', 'a4', 'a3', 'a2', 'c1'], ['c1', 'a4', 'a5', 'a4', 'a1'], ['c3', 'c2'], ['c5', 'b1', 'b3'], ['b3', 'b4', 'b3'], ['b2'], ['b2']]\n"
     ]
    }
   ],
   "source": [
    "# Create \"docs\"\n",
    "np.random.seed(8675309)\n",
    "\n",
    "def gen_doc():\n",
    "    n_topics = np.random.randint(3) + 1\n",
    "    which_topics = np.random.choice(['a', 'b', 'c'], size=n_topics, replace=False)\n",
    "    \n",
    "    s = []\n",
    "    for t in which_topics:\n",
    "        n_words = np.random.randint(4) + 1\n",
    "        which_words = np.random.choice([1, 2, 3, 4, 5], size=n_words, replace=True)\n",
    "        for w in which_words:\n",
    "            s.append(f'{t}{w}')\n",
    "        \n",
    "    return ' '.join(s)\n",
    "\n",
    "docs = [gen_doc() for x in range(10000)]\n",
    "\n",
    "# Split by space\n",
    "docs = [d.split() for d in docs]\n",
    "\n",
    "# Inspect\n",
    "print(docs[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 2), (1, 1), (2, 1), (3, 1)],\n",
       " [(4, 1)],\n",
       " [(4, 1)],\n",
       " [(5, 2), (6, 1), (7, 1), (8, 2), (9, 1)],\n",
       " [(4, 1), (7, 2), (9, 1), (10, 1)]]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create dictionary\n",
    "dic = corpora.Dictionary(docs)\n",
    "\n",
    "# Create bow matrix\n",
    "bow = [dic.doc2bow(doc) for doc in docs]\n",
    "\n",
    "# Inspect\n",
    "bow[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "lda = gensim.models.ldamodel.LdaModel(\n",
    "    bow,\n",
    "    num_topics=3,\n",
    "    id2word = dic,\n",
    "    passes=50,\n",
    "    random_state=666\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.203*\"b1\" + 0.203*\"b2\" + 0.203*\"b4\" + 0.197*\"b3\" + 0.194*\"b5\" + 0.000*\"a3\" + 0.000*\"a5\" + 0.000*\"c4\" + 0.000*\"a1\" + 0.000*\"a2\"'),\n",
       " (1,\n",
       "  '0.197*\"a5\" + 0.197*\"a4\" + 0.192*\"a2\" + 0.191*\"a1\" + 0.191*\"a3\" + 0.033*\"c4\" + 0.000*\"b3\" + 0.000*\"b1\" + 0.000*\"b4\" + 0.000*\"c1\"'),\n",
       " (2,\n",
       "  '0.211*\"c5\" + 0.209*\"c2\" + 0.206*\"c3\" + 0.205*\"c1\" + 0.169*\"c4\" + 0.000*\"a1\" + 0.000*\"b1\" + 0.000*\"b2\" + 0.000*\"a2\" + 0.000*\"b4\"')]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect topics\n",
    "lda.show_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.2 , 0.2 , 0.2 , 0.  , 0.  , 0.  , 0.  , 0.  , 0.19, 0.  , 0.  ,\n",
       "        0.  , 0.  , 0.2 , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  , 0.2 , 0.19, 0.19, 0.2 , 0.  , 0.  , 0.19,\n",
       "        0.  , 0.  , 0.  , 0.03],\n",
       "       [0.  , 0.  , 0.  , 0.21, 0.  , 0.  , 0.  , 0.  , 0.  , 0.2 , 0.  ,\n",
       "        0.21, 0.21, 0.  , 0.17]], dtype=float32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Topic-term matrix\n",
    "np.round(lda.get_topics(), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Topic-term matrix as heatmap\n",
    "words = list(dic.values())\n",
    "words_alphabetical_index = np.argsort(words)\n",
    "words_alphabetical = [words[i] for i in words_alphabetical_index]\n",
    "\n",
    "plt.figure(figsize=(20, 4))\n",
    "sns.heatmap(\n",
    "    lda.get_topics()[:, words_alphabetical_index],\n",
    "    xticklabels=words_alphabetical\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.72, 0.06, 0.22],\n",
       "       [0.17, 0.67, 0.17],\n",
       "       [0.17, 0.67, 0.17],\n",
       "       [0.29, 0.54, 0.17],\n",
       "       [0.06, 0.72, 0.22]], dtype=float32)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Document-topic matrix\n",
    "np.round(get_document_topic_matrix(lda, bow), 2)[:5, :]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
